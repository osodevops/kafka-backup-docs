"use strict";(globalThis.webpackChunkkafka_backup_docs=globalThis.webpackChunkkafka_backup_docs||[]).push([[6453],{2165:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"examples/multi-cluster-dr","title":"Multi-Cluster DR","description":"Disaster recovery across multiple Kafka clusters","source":"@site/docs/examples/multi-cluster-dr.md","sourceDirName":"examples","slug":"/examples/multi-cluster-dr","permalink":"/examples/multi-cluster-dr","draft":false,"unlisted":false,"editUrl":"https://github.com/osodevops/kafka-backup-docs/tree/main/docs/docs/examples/multi-cluster-dr.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Multi-Cluster DR","description":"Disaster recovery across multiple Kafka clusters","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"AWS Lambda","permalink":"/examples/aws-lambda"}}');var s=a(4848),t=a(8453);const i={title:"Multi-Cluster DR",description:"Disaster recovery across multiple Kafka clusters",sidebar_position:4},o="Multi-Cluster Disaster Recovery",c={},l=[{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"Configuration Files",id:"configuration-files",level:2},{value:"Primary Cluster Backup (US-WEST-2)",id:"primary-cluster-backup-us-west-2",level:3},{value:"DR Cluster Restore (US-EAST-1)",id:"dr-cluster-restore-us-east-1",level:3},{value:"S3 Cross-Region Replication",id:"s3-cross-region-replication",level:2},{value:"Enable Replication",id:"enable-replication",level:3},{value:"Replication Configuration",id:"replication-configuration",level:3},{value:"Kubernetes Operator Setup",id:"kubernetes-operator-setup",level:2},{value:"Primary Cluster (US-WEST-2)",id:"primary-cluster-us-west-2",level:3},{value:"DR Cluster (US-EAST-1)",id:"dr-cluster-us-east-1",level:3},{value:"DR Automation Scripts",id:"dr-automation-scripts",level:2},{value:"Failover Script",id:"failover-script",level:3},{value:"Failback Script",id:"failback-script",level:3},{value:"Monitoring and Alerting",id:"monitoring-and-alerting",level:2},{value:"Prometheus Rules",id:"prometheus-rules",level:3},{value:"Grafana Dashboard",id:"grafana-dashboard",level:3},{value:"Testing DR",id:"testing-dr",level:2},{value:"Regular DR Drill",id:"regular-dr-drill",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"multi-cluster-disaster-recovery",children:"Multi-Cluster Disaster Recovery"})}),"\n",(0,s.jsx)(n.p,{children:"This guide demonstrates a comprehensive disaster recovery setup across multiple Kafka clusters in different regions."}),"\n",(0,s.jsx)(n.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Multi-Cluster DR Architecture                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   US-WEST-2 (Primary)              US-EAST-1 (DR)                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502  \u2502   Kafka Cluster     \u2502          \u2502   Kafka Cluster     \u2502                   \u2502\n\u2502  \u2502   (Production)      \u2502          \u2502   (Standby)         \u2502                   \u2502\n\u2502  \u2502                     \u2502          \u2502                     \u2502                   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502                   \u2502\n\u2502  \u2502  \u2502 orders       \u2502   \u2502          \u2502  \u2502 orders       \u2502   \u2502                   \u2502\n\u2502  \u2502  \u2502 payments     \u2502   \u2502          \u2502  \u2502 payments     \u2502   \u2502                   \u2502\n\u2502  \u2502  \u2502 inventory    \u2502   \u2502          \u2502  \u2502 inventory    \u2502   \u2502                   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502             \u2502                                \u2502                               \u2502\n\u2502             \u2502 Backup                         \u2502 Restore                       \u2502\n\u2502             \u25bc                                \u2502                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502  \u2502                    S3 Backup Storage                     \u2502                \u2502\n\u2502  \u2502                                                          \u2502                \u2502\n\u2502  \u2502  s3://kafka-backups/                                     \u2502                \u2502\n\u2502  \u2502  \u251c\u2500\u2500 us-west-2/                                          \u2502                \u2502\n\u2502  \u2502  \u2502   \u251c\u2500\u2500 hourly/                                         \u2502                \u2502\n\u2502  \u2502  \u2502   \u2514\u2500\u2500 daily/                                          \u2502                \u2502\n\u2502  \u2502  \u2514\u2500\u2500 cross-region-replica (us-east-1)                    \u2502                \u2502\n\u2502  \u2502                                                          \u2502                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502                                                                              \u2502\n\u2502   EU-WEST-1 (Analytics)            AP-SOUTHEAST-1 (APAC)                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502  \u2502   Kafka Cluster     \u2502          \u2502   Kafka Cluster     \u2502                   \u2502\n\u2502  \u2502   (Read Replica)    \u2502          \u2502   (Regional)        \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"configuration-files",children:"Configuration Files"}),"\n",(0,s.jsx)(n.h3,{id:"primary-cluster-backup-us-west-2",children:"Primary Cluster Backup (US-WEST-2)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="primary-backup.yaml"',children:'mode: backup\nbackup_id: "primary-${TIMESTAMP}"\n\nsource:\n  bootstrap_servers:\n    - kafka-0.us-west-2.example.com:9092\n    - kafka-1.us-west-2.example.com:9092\n    - kafka-2.us-west-2.example.com:9092\n  security:\n    security_protocol: SASL_SSL\n    sasl_mechanism: SCRAM-SHA-256\n    sasl_username: backup-service\n    sasl_password: ${KAFKA_PASSWORD}\n    ssl_ca_location: /certs/ca.crt\n\n  topics:\n    include:\n      - orders\n      - payments\n      - inventory\n      - customers\n      - "events-*"\n    exclude:\n      - "__consumer_offsets"\n      - "_schemas"\n\nstorage:\n  backend: s3\n  bucket: kafka-backups-primary\n  region: us-west-2\n  prefix: us-west-2/hourly\n\nbackup:\n  compression: zstd\n  compression_level: 3\n  checkpoint_interval_secs: 30\n  include_offset_headers: true\n  source_cluster_id: "prod-us-west-2"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"dr-cluster-restore-us-east-1",children:"DR Cluster Restore (US-EAST-1)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="dr-restore.yaml"',children:'mode: restore\nbackup_id: "${BACKUP_ID}"\n\ntarget:\n  bootstrap_servers:\n    - kafka-0.us-east-1.example.com:9092\n    - kafka-1.us-east-1.example.com:9092\n    - kafka-2.us-east-1.example.com:9092\n  security:\n    security_protocol: SASL_SSL\n    sasl_mechanism: SCRAM-SHA-256\n    sasl_username: restore-service\n    sasl_password: ${KAFKA_PASSWORD}\n    ssl_ca_location: /certs/ca.crt\n\nstorage:\n  backend: s3\n  bucket: kafka-backups-dr\n  region: us-east-1\n  prefix: us-west-2/hourly\n\nrestore:\n  include_original_offset_header: true\n  consumer_group_strategy: header-based\n  reset_consumer_offsets: true\n  consumer_groups:\n    - order-service\n    - payment-processor\n    - inventory-manager\n    - notification-service\n'})}),"\n",(0,s.jsx)(n.h2,{id:"s3-cross-region-replication",children:"S3 Cross-Region Replication"}),"\n",(0,s.jsx)(n.h3,{id:"enable-replication",children:"Enable Replication"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Create replication IAM role\naws iam create-role \\\n  --role-name S3ReplicationRole \\\n  --assume-role-policy-document file://trust-policy.json\n\n# Attach replication policy\naws iam put-role-policy \\\n  --role-name S3ReplicationRole \\\n  --policy-name S3Replication \\\n  --policy-document file://replication-policy.json\n\n# Enable versioning on both buckets\naws s3api put-bucket-versioning \\\n  --bucket kafka-backups-primary \\\n  --versioning-configuration Status=Enabled\n\naws s3api put-bucket-versioning \\\n  --bucket kafka-backups-dr \\\n  --versioning-configuration Status=Enabled\n\n# Configure replication\naws s3api put-bucket-replication \\\n  --bucket kafka-backups-primary \\\n  --replication-configuration file://replication-config.json\n"})}),"\n",(0,s.jsx)(n.h3,{id:"replication-configuration",children:"Replication Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="replication-config.json"',children:'{\n  "Role": "arn:aws:iam::123456789:role/S3ReplicationRole",\n  "Rules": [\n    {\n      "ID": "KafkaBackupReplication",\n      "Status": "Enabled",\n      "Priority": 1,\n      "Filter": {\n        "Prefix": "us-west-2/"\n      },\n      "Destination": {\n        "Bucket": "arn:aws:s3:::kafka-backups-dr",\n        "ReplicationTime": {\n          "Status": "Enabled",\n          "Time": {\n            "Minutes": 15\n          }\n        },\n        "Metrics": {\n          "Status": "Enabled",\n          "EventThreshold": {\n            "Minutes": 15\n          }\n        }\n      },\n      "DeleteMarkerReplication": {\n        "Status": "Disabled"\n      }\n    }\n  ]\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"kubernetes-operator-setup",children:"Kubernetes Operator Setup"}),"\n",(0,s.jsx)(n.h3,{id:"primary-cluster-us-west-2",children:"Primary Cluster (US-WEST-2)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="primary-operator.yaml"',children:'apiVersion: kafka.oso.sh/v1alpha1\nkind: KafkaBackup\nmetadata:\n  name: primary-hourly-backup\n  namespace: kafka-backup\nspec:\n  schedule: "0 * * * *"  # Hourly\n\n  kafkaCluster:\n    bootstrapServers:\n      - kafka-0.us-west-2.example.com:9092\n    securityProtocol: SASL_SSL\n    saslSecret:\n      name: kafka-credentials\n      mechanism: SCRAM-SHA-256\n    tlsSecret:\n      name: kafka-tls\n\n  topics:\n    - orders\n    - payments\n    - inventory\n    - customers\n    - "events-*"\n\n  storage:\n    storageType: s3\n    s3:\n      bucket: kafka-backups-primary\n      region: us-west-2\n      prefix: us-west-2/hourly\n\n  compression: zstd\n  compressionLevel: 3\n  includeOffsetHeaders: true\n  sourceClusterId: "prod-us-west-2"\n\n  retention:\n    backups: 168  # 7 days of hourly backups\n\n---\napiVersion: kafka.oso.sh/v1alpha1\nkind: KafkaBackup\nmetadata:\n  name: primary-daily-backup\n  namespace: kafka-backup\nspec:\n  schedule: "0 2 * * *"  # Daily at 2 AM\n\n  kafkaCluster:\n    bootstrapServers:\n      - kafka-0.us-west-2.example.com:9092\n    securityProtocol: SASL_SSL\n    saslSecret:\n      name: kafka-credentials\n      mechanism: SCRAM-SHA-256\n\n  topics:\n    - "*"\n  excludeTopics:\n    - "__*"\n    - "_*"\n\n  storage:\n    storageType: s3\n    s3:\n      bucket: kafka-backups-primary\n      region: us-west-2\n      prefix: us-west-2/daily\n\n  compression: zstd\n  compressionLevel: 6  # Higher compression for archival\n  includeOffsetHeaders: true\n  sourceClusterId: "prod-us-west-2"\n\n  retention:\n    backups: 90  # 90 days of daily backups\n'})}),"\n",(0,s.jsx)(n.h3,{id:"dr-cluster-us-east-1",children:"DR Cluster (US-EAST-1)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="dr-restore-operator.yaml"',children:'apiVersion: kafka.oso.sh/v1alpha1\nkind: KafkaRestore\nmetadata:\n  name: dr-restore\n  namespace: kafka-backup\nspec:\n  # Triggered manually or by automation\n  backupId: "primary-20241201-120000"\n\n  targetCluster:\n    bootstrapServers:\n      - kafka-0.us-east-1.example.com:9092\n    securityProtocol: SASL_SSL\n    saslSecret:\n      name: kafka-credentials\n      mechanism: SCRAM-SHA-256\n\n  storage:\n    storageType: s3\n    s3:\n      bucket: kafka-backups-dr\n      region: us-east-1\n      prefix: us-west-2/hourly\n\n  offsetReset:\n    strategy: headerBased\n    sourceCluster: "prod-us-west-2"\n    consumerGroups:\n      - order-service\n      - payment-processor\n      - inventory-manager\n'})}),"\n",(0,s.jsx)(n.h2,{id:"dr-automation-scripts",children:"DR Automation Scripts"}),"\n",(0,s.jsx)(n.h3,{id:"failover-script",children:"Failover Script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# failover.sh - Execute DR failover\n\nset -e\n\nBACKUP_PATH="s3://kafka-backups-dr/us-west-2/hourly"\nDR_CLUSTER="kafka-0.us-east-1.example.com:9092"\nNAMESPACE="kafka-backup"\n\necho "=========================================="\necho "  KAFKA DR FAILOVER"\necho "  $(date)"\necho "=========================================="\n\n# Step 1: Find latest backup\necho "[1/6] Finding latest backup..."\nLATEST_BACKUP=$(kafka-backup list --path "$BACKUP_PATH" --format json | jq -r \'.backups[-1].backup_id\')\necho "      Latest backup: $LATEST_BACKUP"\n\n# Step 2: Validate backup\necho "[2/6] Validating backup..."\nkafka-backup validate --path "$BACKUP_PATH" --backup-id "$LATEST_BACKUP" --deep\n\n# Step 3: Scale down applications (optional, if running in DR)\necho "[3/6] Scaling down DR applications..."\nkubectl scale deployment -n production -l tier=kafka-consumer --replicas=0\n\n# Step 4: Execute restore\necho "[4/6] Restoring data to DR cluster..."\ncat > /tmp/dr-restore.yaml << EOF\nmode: restore\nbackup_id: "$LATEST_BACKUP"\n\ntarget:\n  bootstrap_servers:\n    - $DR_CLUSTER\n  security:\n    security_protocol: SASL_SSL\n    sasl_mechanism: SCRAM-SHA-256\n    sasl_username: restore-service\n    sasl_password: \\${KAFKA_PASSWORD}\n\nstorage:\n  backend: s3\n  bucket: kafka-backups-dr\n  region: us-east-1\n  prefix: us-west-2/hourly\n\nrestore:\n  include_original_offset_header: true\n  consumer_group_strategy: header-based\n  reset_consumer_offsets: true\n  consumer_groups:\n    - order-service\n    - payment-processor\n    - inventory-manager\n    - notification-service\nEOF\n\nkafka-backup three-phase-restore --config /tmp/dr-restore.yaml\n\n# Step 5: Verify restore\necho "[5/6] Verifying restore..."\nkafka-topics --bootstrap-server "$DR_CLUSTER" --list\nkafka-consumer-groups --bootstrap-server "$DR_CLUSTER" --list\n\n# Step 6: Scale up applications\necho "[6/6] Scaling up DR applications..."\nkubectl scale deployment -n production -l tier=kafka-consumer --replicas=3\n\necho "=========================================="\necho "  FAILOVER COMPLETE"\necho "  DR Cluster: $DR_CLUSTER"\necho "  Backup Used: $LATEST_BACKUP"\necho "=========================================="\n'})}),"\n",(0,s.jsx)(n.h3,{id:"failback-script",children:"Failback Script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# failback.sh - Return to primary after DR event\n\nset -e\n\nPRIMARY_CLUSTER="kafka-0.us-west-2.example.com:9092"\nDR_CLUSTER="kafka-0.us-east-1.example.com:9092"\n\necho "=========================================="\necho "  KAFKA DR FAILBACK"\necho "  $(date)"\necho "=========================================="\n\n# Step 1: Backup DR cluster (capture changes made during DR)\necho "[1/5] Backing up DR cluster changes..."\nkafka-backup backup --config dr-backup.yaml\n\n# Step 2: Verify primary is healthy\necho "[2/5] Verifying primary cluster health..."\nkafka-broker-api-versions --bootstrap-server "$PRIMARY_CLUSTER"\n\n# Step 3: Sync DR changes to primary\necho "[3/5] Syncing DR changes to primary..."\n# This restores only the delta (changes made during DR event)\nkafka-backup restore --config failback-restore.yaml\n\n# Step 4: Reset consumer offsets on primary\necho "[4/5] Resetting consumer offsets..."\nkafka-backup offset-reset execute \\\n  --bootstrap-servers "$PRIMARY_CLUSTER" \\\n  --strategy timestamp \\\n  --timestamp "$(date +%s000)" \\\n  --groups order-service,payment-processor,inventory-manager\n\n# Step 5: Redirect traffic back to primary\necho "[5/5] Redirecting traffic to primary..."\n# Update DNS, load balancer, or service mesh configuration\nkubectl patch configmap kafka-config -n production \\\n  --patch \'{"data":{"bootstrap.servers":"kafka-0.us-west-2.example.com:9092"}}\'\n\n# Restart applications to pick up new config\nkubectl rollout restart deployment -n production -l tier=kafka-consumer\n\necho "=========================================="\necho "  FAILBACK COMPLETE"\necho "  Primary Cluster: $PRIMARY_CLUSTER"\necho "=========================================="\n'})}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-and-alerting",children:"Monitoring and Alerting"}),"\n",(0,s.jsx)(n.h3,{id:"prometheus-rules",children:"Prometheus Rules"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",metastring:'title="prometheus-rules.yaml"',children:'apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: kafka-backup-alerts\n  namespace: monitoring\nspec:\n  groups:\n    - name: kafka-backup\n      rules:\n        # Backup failure alert\n        - alert: KafkaBackupFailed\n          expr: kafka_backup_backups_total{outcome="failure"} > 0\n          for: 5m\n          labels:\n            severity: critical\n          annotations:\n            summary: "Kafka backup failed"\n            description: "Backup {{ $labels.backup_id }} failed"\n\n        # Backup lag alert\n        - alert: KafkaBackupLag\n          expr: time() - kafka_backup_last_successful_backup_timestamp > 7200\n          for: 5m\n          labels:\n            severity: warning\n          annotations:\n            summary: "Kafka backup lag"\n            description: "No successful backup in 2 hours"\n\n        # S3 replication lag\n        - alert: S3ReplicationLag\n          expr: aws_s3_replication_latency_seconds > 1800\n          for: 5m\n          labels:\n            severity: warning\n          annotations:\n            summary: "S3 cross-region replication lag"\n            description: "Replication lag exceeds 30 minutes"\n\n        # DR readiness\n        - alert: DRNotReady\n          expr: kafka_backup_dr_ready == 0\n          for: 15m\n          labels:\n            severity: critical\n          annotations:\n            summary: "DR cluster not ready"\n            description: "DR cluster has not received recent backups"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"grafana-dashboard",children:"Grafana Dashboard"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",metastring:'title="dr-dashboard.json"',children:'{\n  "dashboard": {\n    "title": "Multi-Cluster DR Status",\n    "panels": [\n      {\n        "title": "Backup Status",\n        "type": "stat",\n        "targets": [\n          {\n            "expr": "kafka_backup_last_successful_backup_timestamp"\n          }\n        ]\n      },\n      {\n        "title": "Replication Lag",\n        "type": "gauge",\n        "targets": [\n          {\n            "expr": "time() - kafka_backup_last_successful_backup_timestamp"\n          }\n        ],\n        "thresholds": {\n          "steps": [\n            { "value": 0, "color": "green" },\n            { "value": 3600, "color": "yellow" },\n            { "value": 7200, "color": "red" }\n          ]\n        }\n      },\n      {\n        "title": "Backup Size Trend",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "kafka_backup_backup_size_bytes"\n          }\n        ]\n      },\n      {\n        "title": "Records Backed Up",\n        "type": "graph",\n        "targets": [\n          {\n            "expr": "rate(kafka_backup_records_total[1h])"\n          }\n        ]\n      }\n    ]\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"testing-dr",children:"Testing DR"}),"\n",(0,s.jsx)(n.h3,{id:"regular-dr-drill",children:"Regular DR Drill"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# dr-drill.sh - Monthly DR test\n\necho "Starting DR Drill..."\n\n# 1. Create test topic in primary\nkafka-topics --create --topic dr-test-$(date +%Y%m%d) \\\n  --bootstrap-server primary-kafka:9092\n\n# 2. Produce test messages\nkafka-producer-perf-test \\\n  --topic dr-test-$(date +%Y%m%d) \\\n  --num-records 10000 \\\n  --record-size 1000 \\\n  --throughput -1 \\\n  --producer-props bootstrap.servers=primary-kafka:9092\n\n# 3. Trigger backup\nkafka-backup backup --config primary-backup.yaml\n\n# 4. Wait for S3 replication\nsleep 300\n\n# 5. Restore to DR\nkafka-backup restore --config dr-restore.yaml\n\n# 6. Verify data in DR\nCOUNT=$(kafka-run-class kafka.tools.GetOffsetShell \\\n  --broker-list dr-kafka:9092 \\\n  --topic dr-test-$(date +%Y%m%d) | awk -F: \'{sum+=$3} END {print sum}\')\n\nif [ "$COUNT" -eq "10000" ]; then\n  echo "DR Drill PASSED: All records restored"\nelse\n  echo "DR Drill FAILED: Expected 10000, got $COUNT"\n  exit 1\nfi\n\n# 7. Cleanup\nkafka-topics --delete --topic dr-test-$(date +%Y%m%d) \\\n  --bootstrap-server primary-kafka:9092\nkafka-topics --delete --topic dr-test-$(date +%Y%m%d) \\\n  --bootstrap-server dr-kafka:9092\n\necho "DR Drill Complete"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Automate backups"})," - Use scheduled backups via operator or cron"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enable S3 replication"})," - Cross-region replication for DR bucket"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Test DR regularly"})," - Monthly DR drills"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor replication lag"})," - Alert on backup and replication delays"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Document runbooks"})," - Clear procedures for failover/failback"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Secure credentials"})," - Use secrets management for all clusters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Version control configs"})," - GitOps for backup/restore configurations"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../use-cases/disaster-recovery",children:"Disaster Recovery Guide"})," - DR planning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../operator",children:"Kubernetes Operator"})," - Operator setup"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../use-cases/compliance-audit",children:"Compliance"})," - Meeting compliance requirements"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>i,x:()=>o});var r=a(6540);const s={},t=r.createContext(s);function i(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);