"use strict";(globalThis.webpackChunkkafka_backup_docs=globalThis.webpackChunkkafka_backup_docs||[]).push([[7291],{3367:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>t});const r=JSON.parse('{"id":"troubleshooting/performance-issues","title":"Performance Issues","description":"Troubleshooting slow backup and restore operations","source":"@site/docs/troubleshooting/performance-issues.md","sourceDirName":"troubleshooting","slug":"/troubleshooting/performance-issues","permalink":"/troubleshooting/performance-issues","draft":false,"unlisted":false,"editUrl":"https://github.com/osodevops/kafka-backup-docs/tree/main/docs/docs/troubleshooting/performance-issues.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Performance Issues","description":"Troubleshooting slow backup and restore operations","sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Common Errors","permalink":"/troubleshooting/common-errors"},"next":{"title":"Offset Discontinuity","permalink":"/troubleshooting/offset-discontinuity"}}');var i=s(4848),a=s(8453);const l={title:"Performance Issues",description:"Troubleshooting slow backup and restore operations",sidebar_position:2},o="Performance Issues",c={},t=[{value:"Diagnosing Performance Problems",id:"diagnosing-performance-problems",level:2},{value:"Check Current Throughput",id:"check-current-throughput",level:3},{value:"Expected Performance",id:"expected-performance",level:3},{value:"Backup Performance",id:"backup-performance",level:2},{value:"Problem: Slow Kafka Consumption",id:"problem-slow-kafka-consumption",level:3},{value:"Problem: Network Bottleneck",id:"problem-network-bottleneck",level:3},{value:"Problem: Slow Compression",id:"problem-slow-compression",level:3},{value:"Problem: Slow Storage Writes",id:"problem-slow-storage-writes",level:3},{value:"Problem: Single Partition Bottleneck",id:"problem-single-partition-bottleneck",level:3},{value:"Restore Performance",id:"restore-performance",level:2},{value:"Problem: Slow Kafka Production",id:"problem-slow-kafka-production",level:3},{value:"Problem: Slow Decompression",id:"problem-slow-decompression",level:3},{value:"Problem: Slow PITR Filtering",id:"problem-slow-pitr-filtering",level:3},{value:"Resource Optimization",id:"resource-optimization",level:2},{value:"Memory Tuning",id:"memory-tuning",level:3},{value:"CPU Tuning",id:"cpu-tuning",level:3},{value:"Parallelism",id:"parallelism",level:3},{value:"Storage-Specific Optimization",id:"storage-specific-optimization",level:2},{value:"S3 Performance",id:"s3-performance",level:3},{value:"Azure Blob Performance",id:"azure-blob-performance",level:3},{value:"GCS Performance",id:"gcs-performance",level:3},{value:"Local/PVC Performance",id:"localpvc-performance",level:3},{value:"Monitoring Performance",id:"monitoring-performance",level:2},{value:"Prometheus Metrics",id:"prometheus-metrics",level:3},{value:"Grafana Dashboard",id:"grafana-dashboard",level:3},{value:"Real-time Monitoring",id:"real-time-monitoring",level:3},{value:"Performance Checklist",id:"performance-checklist",level:2},{value:"Before Backup",id:"before-backup",level:3},{value:"During Backup",id:"during-backup",level:3},{value:"After Backup",id:"after-backup",level:3},{value:"Benchmarking",id:"benchmarking",level:2},{value:"Baseline Test",id:"baseline-test",level:3},{value:"Compare Configurations",id:"compare-configurations",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"performance-issues",children:"Performance Issues"})}),"\n",(0,i.jsx)(n.p,{children:"This guide helps diagnose and resolve slow backup and restore operations."}),"\n",(0,i.jsx)(n.h2,{id:"diagnosing-performance-problems",children:"Diagnosing Performance Problems"}),"\n",(0,i.jsx)(n.h3,{id:"check-current-throughput",children:"Check Current Throughput"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Monitor backup progress\nkafka-backup status --config backup.yaml --watch\n\n# Output includes:\n# Records/sec: 50,000\n# Bytes/sec: 25 MB/s\n# Estimated completion: 2h 15m\n"})}),"\n",(0,i.jsx)(n.h3,{id:"expected-performance",children:"Expected Performance"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Operation"}),(0,i.jsx)(n.th,{children:"Per Partition"}),(0,i.jsx)(n.th,{children:"With 10 Partitions"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Backup"}),(0,i.jsx)(n.td,{children:"50-100 MB/s"}),(0,i.jsx)(n.td,{children:"500 MB/s - 1 GB/s"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Restore"}),(0,i.jsx)(n.td,{children:"75-150 MB/s"}),(0,i.jsx)(n.td,{children:"750 MB/s - 1.5 GB/s"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"If you're seeing significantly lower numbers, continue troubleshooting."}),"\n",(0,i.jsx)(n.h2,{id:"backup-performance",children:"Backup Performance"}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-kafka-consumption",children:"Problem: Slow Kafka Consumption"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Low records/sec"}),"\n",(0,i.jsx)(n.li,{children:"High CPU idle"}),"\n",(0,i.jsx)(n.li,{children:"Storage I/O is fine"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check consumer lag\nkafka-consumer-groups --bootstrap-server kafka:9092 \\\n  --describe --group kafka-backup-$BACKUP_ID\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Increase fetch sizes\nsource:\n  kafka_config:\n    fetch.max.bytes: 104857600          # 100 MB\n    max.partition.fetch.bytes: 10485760  # 10 MB per partition\n    fetch.min.bytes: 1048576             # 1 MB minimum\n    fetch.max.wait.ms: 500               # Wait for batches\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-network-bottleneck",children:"Problem: Network Bottleneck"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Throughput limited regardless of settings"}),"\n",(0,i.jsx)(n.li,{children:"Network utilization at 100%"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check network utilization\niftop -i eth0\n\n# Test network bandwidth\niperf3 -c kafka-broker-0 -p 5201\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Compress before transfer:"})}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"backup:\n  compression: zstd\n  compression_level: 1  # Fast compression\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Use closer storage region:"})}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: s3\n  region: us-west-2  # Same region as Kafka\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Enable VPC endpoints:"})}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: s3\n  endpoint: https://s3.us-west-2.amazonaws.com\n  use_vpc_endpoint: true\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-compression",children:"Problem: Slow Compression"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"High CPU utilization"}),"\n",(0,i.jsx)(n.li,{children:"Compression taking most of the time"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check CPU during backup\ntop -p $(pgrep kafka-backup)\n\n# Check metrics\ncurl localhost:9090/metrics | grep compression\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Use faster compression\nbackup:\n  compression: lz4  # Faster than zstd\n  # Or reduce level\n  compression: zstd\n  compression_level: 1  # Fastest\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-storage-writes",children:"Problem: Slow Storage Writes"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Low storage throughput"}),"\n",(0,i.jsx)(n.li,{children:"High storage latency"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Test S3 write speed\ndd if=/dev/zero bs=1M count=100 | aws s3 cp - s3://bucket/test-file\n\n# Check CloudWatch metrics for S3\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Optimize multipart uploads\nstorage:\n  backend: s3\n  multipart_threshold: 52428800    # 50 MB\n  multipart_part_size: 10485760    # 10 MB\n  max_concurrent_uploads: 10\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-single-partition-bottleneck",children:"Problem: Single Partition Bottleneck"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"One partition much slower than others"}),"\n",(0,i.jsx)(n.li,{children:"Uneven partition sizes"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check partition sizes\nkafka-log-dirs --bootstrap-server kafka:9092 --describe\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"For future: Use better partition keys"}),"\n",(0,i.jsx)(n.li,{children:"For now: Accept longer backup time for skewed partitions"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"restore-performance",children:"Restore Performance"}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-kafka-production",children:"Problem: Slow Kafka Production"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Low write throughput"}),"\n",(0,i.jsx)(n.li,{children:"Producer backpressure"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check producer metrics\nkafka-backup status --config restore.yaml --watch\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Optimize producer settings\ntarget:\n  kafka_config:\n    batch.size: 1048576        # 1 MB batches\n    linger.ms: 100             # Wait for batches\n    buffer.memory: 67108864    # 64 MB buffer\n    acks: 1                    # Trade durability for speed\n    compression.type: lz4      # Producer-side compression\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-decompression",children:"Problem: Slow Decompression"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reading from storage is fine"}),"\n",(0,i.jsx)(n.li,{children:"CPU bound during restore"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Use faster decompression (for future backups)\nbackup:\n  compression: lz4  # Decompresses faster than zstd\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-slow-pitr-filtering",children:"Problem: Slow PITR Filtering"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Symptoms:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"PITR restore much slower than full restore"}),"\n",(0,i.jsx)(n.li,{children:"Many segments being read but few records restored"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Diagnosis:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check how many records match time window\nkafka-backup describe \\\n  --path s3://bucket/backups \\\n  --backup-id my-backup \\\n  --format json | jq '.segments[] | select(.start_timestamp < 1701388800000)'\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Ensure time window aligns with segment boundaries\n# Backups with shorter checkpoint intervals = better PITR performance\nbackup:\n  checkpoint_interval_secs: 30  # More granular segments\n"})}),"\n",(0,i.jsx)(n.h2,{id:"resource-optimization",children:"Resource Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"memory-tuning",children:"Memory Tuning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Reduce memory for constrained environments\nbackup:\n  batch_size: 10000           # Fewer records per batch\n  max_batch_bytes: 52428800   # 50 MB max\n\n# Increase memory for better throughput\nbackup:\n  batch_size: 100000          # More records per batch\n  max_batch_bytes: 209715200  # 200 MB max\n"})}),"\n",(0,i.jsx)(n.h3,{id:"cpu-tuning",children:"CPU Tuning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# Reduce CPU usage\nbackup:\n  compression: lz4           # Lower CPU\n  compression_level: 1\n\n# Maximize throughput (more CPU)\nbackup:\n  compression: zstd\n  compression_level: 3\n  # Parallel compression across partitions\n"})}),"\n",(0,i.jsx)(n.h3,{id:"parallelism",children:"Parallelism"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# More parallelism (higher resource usage)\nbackup:\n  parallel_partitions: 20    # Process more partitions concurrently\n\n# Less parallelism (lower resource usage)\nbackup:\n  parallel_partitions: 4\n"})}),"\n",(0,i.jsx)(n.h2,{id:"storage-specific-optimization",children:"Storage-Specific Optimization"}),"\n",(0,i.jsx)(n.h3,{id:"s3-performance",children:"S3 Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: s3\n  bucket: my-bucket\n  region: us-west-2\n\n  # Transfer acceleration\n  use_accelerate_endpoint: true\n\n  # Multipart optimization\n  multipart_threshold: 52428800\n  multipart_part_size: 10485760\n  max_concurrent_uploads: 20\n\n  # Connection pooling\n  max_connections: 50\n"})}),"\n",(0,i.jsx)(n.h3,{id:"azure-blob-performance",children:"Azure Blob Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: azure\n  container: kafka-backups\n\n  # Block blob settings\n  block_size: 10485760      # 10 MB blocks\n  max_concurrency: 10\n"})}),"\n",(0,i.jsx)(n.h3,{id:"gcs-performance",children:"GCS Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: gcs\n  bucket: kafka-backups\n\n  # Parallel composite uploads\n  parallel_composite_upload: true\n  chunk_size: 10485760      # 10 MB chunks\n"})}),"\n",(0,i.jsx)(n.h3,{id:"localpvc-performance",children:"Local/PVC Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"storage:\n  backend: local\n  path: /backups\n\n  # Use SSD if available\n  # Ensure sufficient IOPS\n"})}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-performance",children:"Monitoring Performance"}),"\n",(0,i.jsx)(n.h3,{id:"prometheus-metrics",children:"Prometheus Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-promql",children:"# Backup throughput\nrate(kafka_backup_bytes_total[5m])\n\n# Records per second\nrate(kafka_backup_records_total[5m])\n\n# Compression ratio\nkafka_backup_compression_ratio\n\n# Batch processing time (p99)\nhistogram_quantile(0.99, kafka_backup_batch_duration_seconds_bucket)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"grafana-dashboard",children:"Grafana Dashboard"}),"\n",(0,i.jsx)(n.p,{children:"Key panels to monitor:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Throughput (MB/s) over time"}),"\n",(0,i.jsx)(n.li,{children:"Records/sec per partition"}),"\n",(0,i.jsx)(n.li,{children:"Compression ratio"}),"\n",(0,i.jsx)(n.li,{children:"Checkpoint latency"}),"\n",(0,i.jsx)(n.li,{children:"Storage write latency"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"real-time-monitoring",children:"Real-time Monitoring"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Watch backup progress\nkafka-backup backup --config backup.yaml --progress\n\n# Output:\n# Progress: 45% (450,000/1,000,000 records)\n# Speed: 85 MB/s\n# ETA: 10 minutes\n"})}),"\n",(0,i.jsx)(n.h2,{id:"performance-checklist",children:"Performance Checklist"}),"\n",(0,i.jsx)(n.h3,{id:"before-backup",children:"Before Backup"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Kafka cluster has capacity for backup consumer"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Storage bucket is in same region as Kafka"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Network allows sufficient bandwidth"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Compression level matches needs (speed vs size)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"during-backup",children:"During Backup"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Monitor throughput metrics"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Check for consumer lag"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Verify checkpoint writes succeeding"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Watch for rate limiting errors"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"after-backup",children:"After Backup"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Verify backup size is reasonable"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Check compression ratio"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Note total duration for planning"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Run validation"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"benchmarking",children:"Benchmarking"}),"\n",(0,i.jsx)(n.h3,{id:"baseline-test",children:"Baseline Test"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Test maximum throughput to storage\ndd if=/dev/zero bs=1M count=1000 | \\\n  aws s3 cp - s3://bucket/benchmark/test-1gb\n\n# Test maximum throughput from Kafka\nkafka-consumer-perf-test \\\n  --bootstrap-server kafka:9092 \\\n  --topic orders \\\n  --messages 1000000 \\\n  --threads 4\n"})}),"\n",(0,i.jsx)(n.h3,{id:"compare-configurations",children:"Compare Configurations"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Test with different compression\nfor level in 1 3 6 9; do\n  kafka-backup backup \\\n    --config backup.yaml \\\n    --compression-level $level \\\n    --dry-run \\\n    --benchmark\ndone\n"})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"./debug-mode",children:"Debug Mode"})," - Enable verbose logging"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"../guides/performance-tuning",children:"Performance Tuning Guide"})," - Optimization strategies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"../architecture/zero-copy-optimization",children:"Architecture"})," - Understanding internals"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var r=s(6540);const i={},a=r.createContext(i);function l(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);